#!/usr/bin/env python3
"""
ja-minimal ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã® Provence ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import logging
from pathlib import Path
from datasets import load_dataset

from sentence_transformers.provence import (
    ProvenceEncoder,
    ProvenceTrainer,
    ProvenceChunkBasedDataCollator
)
from sentence_transformers.provence.losses_chunk_based import ProvenceChunkBasedLoss

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    print("=== ja-minimal ã§ã® Provence ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ ===")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = "./outputs/provence-ja-minimal"
    os.makedirs(output_dir, exist_ok=True)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ‰
    print("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ‰ä¸­...")
    dataset = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'ja-minimal')
    
    print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(dataset['train']):,} ä»¶")
    print(f"âœ… è©•ä¾¡ãƒ‡ãƒ¼ã‚¿: {len(dataset['validation']):,} ä»¶")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    model = ProvenceEncoder(
        model_name_or_path="hotchpotch/japanese-reranker-xsmall-v2",
        num_labels=1,
        max_length=512,
        pruning_config={
            "dropout": 0.1,
            "sentence_pooling": "mean"
        }
    )
    
    # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ï¼ˆHuggingFace Datasetsã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
    data_collator = ProvenceChunkBasedDataCollator(
        tokenizer=model.tokenizer,
        max_length=512,
        padding=True,
        truncation=True,
        # åˆ—åã‚’æŒ‡å®š
        query_column="query",
        texts_column="texts",
        labels_column="labels",
        scores_column="teacher_scores_japanese-reranker-xsmall-v2",  # Teacher scoresã‚’ä½¿ç”¨
        chunks_pos_column="chunks_pos",
        relevant_chunks_column="relevant_chunks"
    )
    
    # æå¤±é–¢æ•°ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
    loss_fn = ProvenceChunkBasedLoss(
        model=model,
        ranking_weight=1.0,
        pruning_weight=0.8,  # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°é‡è¦–
        is_regression=True   # Teacher score distillation
    )
    
    # å­¦ç¿’è¨­å®šï¼ˆå¤§å®¹é‡GPUç”¨ï¼‰
    training_args = {
        "output_dir": output_dir,
        "num_epochs": 2,  # æ¤œè¨¼ç”¨ã«çŸ­ç¸®
        "batch_size": 48,  # å¤§å®¹é‡GPUãƒ¡ãƒ¢ãƒªåˆ©ç”¨
        "learning_rate": 2e-5,
        "warmup_ratio": 0.1,
        "weight_decay": 0.01,
        "gradient_accumulation_steps": 1,  # å®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚º48
        "max_grad_norm": 1.0,
        "logging_steps": 20,  # ã‚ˆã‚Šé »ç¹ã«ãƒ­ã‚°å‡ºåŠ›
        "eval_steps": 200,  # ã‚ˆã‚Šé »ç¹ã«è©•ä¾¡
        "save_steps": 200,  # ã‚ˆã‚Šé »ç¹ã«ä¿å­˜
        "save_total_limit": 3,
        "fp16": True,
        "dataloader_num_workers": 4,  # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é«˜é€ŸåŒ–
        "seed": 42
    }
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
    print("ğŸš€ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–ä¸­...")
    trainer = ProvenceTrainer(
        model=model,
        train_dataset=dataset['train'],  # HuggingFace Datasetã‚’ãã®ã¾ã¾æ¸¡ã™
        eval_dataset=dataset['validation'],
        data_collator=data_collator,
        loss_fn=loss_fn,
        training_args=training_args
    )
    
    # å­¦ç¿’é–‹å§‹
    print(f"ğŸ¯ å­¦ç¿’é–‹å§‹ - ja-minimal ({len(dataset['train']):,} ä»¶)")
    print(f"ğŸ“ å‡ºåŠ›å…ˆ: {output_dir}")
    print(f"âš™ï¸  è¨­å®š: ã‚¨ãƒãƒƒã‚¯æ•°={training_args['num_epochs']}, ãƒãƒƒãƒã‚µã‚¤ã‚º={training_args['batch_size']}, å®ŸåŠ¹BS={training_args['batch_size'] * training_args['gradient_accumulation_steps']}")
    
    try:
        trainer.train()
        print("âœ… å­¦ç¿’å®Œäº†!")
        
        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        final_model_path = os.path.join(output_dir, "final-model")
        model.save_pretrained(final_model_path)
        print(f"ğŸ’¾ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {final_model_path}")
        
    except Exception as e:
        logger.error(f"âŒ å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        raise

if __name__ == "__main__":
    main()