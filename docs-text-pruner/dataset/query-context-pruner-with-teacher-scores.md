# Query-Context Prunerãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ•™å¸«ã‚¹ã‚³ã‚¢ä»˜ãï¼‰

ç‰¹ã«æŒ‡ç¤ºãŒãªã‘ã‚Œã°ã€æ—¥æœ¬èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(ja-full, ja-small, ja-minimal)ã‚’ä½¿ã†ã“ã¨ã€‚

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€Query-Context Pruningã‚¿ã‚¹ã‚¯ç”¨ã®é«˜å“è³ªãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚japanese-reranker-xsmall-v2ã«ã‚ˆã‚‹æ•™å¸«ã‚¹ã‚³ã‚¢ã¨vLLMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒä»˜ä¸ã•ã‚Œã¦ãŠã‚Šã€åŠ¹ç‡çš„ãªãƒãƒ£ãƒ³ã‚¯ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

**ãƒªãƒã‚¸ãƒˆãƒª**: `hotchpotch/wip-query-context-pruner-with-teacher-scores`ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆï¼‰

## ğŸŒŸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—

### ğŸŒ **å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç‰ˆ**ï¼ˆå¤šè¨€èªãƒ»å¤šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±åˆï¼‰
**ç”¨é€”**: åŒ…æ‹¬çš„ãªç ”ç©¶ãƒ»è©•ä¾¡ã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«å¯¾å¿œ

```python
from datasets import load_dataset

# ãƒ•ãƒ«ç‰ˆï¼ˆ129ä¸‡ä»¶ï¼‰- ç ”ç©¶ãƒ»è©•ä¾¡ç”¨
full_dataset = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'full')

# ã‚¹ãƒ¢ãƒ¼ãƒ«ç‰ˆï¼ˆ10ä¸‡ä»¶ï¼‰- é–‹ç™ºãƒ»å®Ÿé¨“ç”¨
small_dataset = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'small')

# ãƒŸãƒ‹ãƒãƒ«ç‰ˆï¼ˆ1ä¸‡ä»¶ï¼‰- é«˜é€Ÿãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ç”¨
minimal_dataset = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'minimal')
```

**ç‰¹å¾´**:
- **11ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±åˆ**: MS-MARCOï¼ˆè‹±èªãƒ»æ—¥æœ¬èªï¼‰ã€HPPRC 8ç¨®ã€MIRACL 18è¨€èª
- **å¤šè¨€èªå¯¾å¿œ**: 20è¨€èªï¼ˆæ—¥æœ¬èªã€è‹±èªã€ã‚¢ãƒ©ãƒ“ã‚¢èªã€ä¸­å›½èªãªã©ï¼‰
- **ãƒãƒ©ãƒ³ã‚¹åˆ†å‰²**: dataset_nameåˆ¥ã«é©åˆ‡ãªæ¯”ç‡ã§train/validation/teståˆ†å‰²
- **æ•™å¸«ã‚¹ã‚³ã‚¢**: POSå¹³å‡ 0.78-0.82ã€NEGå¹³å‡ 0.15-0.19

---

### ğŸ‡ºğŸ‡¸ **MS-MARCOè‹±èªç‰ˆ**ï¼ˆè‹±èªç‰¹åŒ–ï¼‰
**ç”¨é€”**: è‹±èªå°‚ç”¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€MS-MARCOãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¯¾å¿œ

```python
# ãƒ•ãƒ«ç‰ˆï¼ˆ50ä¸‡ä»¶ï¼‰- è‹±èªãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨
ms_marco_full = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'ms-marco-full')

# ã‚¹ãƒ¢ãƒ¼ãƒ«ç‰ˆï¼ˆ10ä¸‡ä»¶ï¼‰- è‹±èªé–‹ç™ºç”¨
ms_marco_small = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'ms-marco-small')

# ãƒŸãƒ‹ãƒãƒ«ç‰ˆï¼ˆ1ä¸‡ä»¶ï¼‰- è‹±èªãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ç”¨
ms_marco_minimal = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'ms-marco-minimal')
```

**ç‰¹å¾´**:
- **ç´”ç²‹è‹±èª**: MS-MARCOè‹±èªãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼ˆdataset_name='ms-marco'ï¼‰
- **é«˜å“è³ª**: æ•™å¸«ã‚¹ã‚³ã‚¢ POSå¹³å‡ 0.73-0.80ã€NEGå¹³å‡ 0.12-0.18
- **æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**: MS-MARCOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¨™æº–å½¢å¼
- **åŠ¹ç‡çš„ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°**: NLTK sentence tokenizationã«ã‚ˆã‚‹æœ€é©åŒ–

---

### ğŸ‡¯ğŸ‡µ **æ—¥æœ¬èªç‰ˆ**ï¼ˆæ—¥æœ¬èªç‰¹åŒ–ã€MS-MARCOé™¤å¤–ï¼‰
**ç”¨é€”**: æ—¥æœ¬èªå°‚ç”¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€æ—¥æœ¬èªNLPç ”ç©¶

```python
# ãƒ•ãƒ«ç‰ˆï¼ˆ50ä¸‡ä»¶ï¼‰- æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨
ja_full = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'ja-full')

# ã‚¹ãƒ¢ãƒ¼ãƒ«ç‰ˆï¼ˆ10ä¸‡ä»¶ï¼‰- æ—¥æœ¬èªé–‹ç™ºç”¨  
ja_small = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'ja-small')

# ãƒŸãƒ‹ãƒãƒ«ç‰ˆï¼ˆ1ä¸‡ä»¶ï¼‰- æ—¥æœ¬èªãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ç”¨
ja_minimal = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'ja-minimal')
```

**ç‰¹å¾´**:
- **ç´”ç²‹æ—¥æœ¬èª**: ms-marco-jaã€miracl-jaã€HPPRCæ—¥æœ¬èªç³»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- **æœ€é«˜å“è³ª**: æ•™å¸«ã‚¹ã‚³ã‚¢ POSå¹³å‡ 0.74-0.98ï¼ˆå…¨ç‰ˆä¸­æœ€é«˜ï¼‰
- **æ—¥æœ¬èªæœ€é©åŒ–**: æ—¥æœ¬èªæ–‡åˆ†å‰²ï¼ˆbunkaiï¼‰ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
- **åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿**: MS-MARCOæ—¥æœ¬èªç‰ˆ + MIRACLæ—¥æœ¬èª + HPPRCæ—¥æœ¬èªç³»

---

## ğŸ“Š **ãƒ‡ãƒ¼ã‚¿æ§‹é€ **

ã™ã¹ã¦ã®subsetã§çµ±ä¸€ã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒï¼š

```python
{
    'id': str,                                           # ãƒ¦ãƒ‹ãƒ¼ã‚¯ID
    'query': str,                                        # æ¤œç´¢ã‚¯ã‚¨ãƒª
    'texts': List[str],                                  # 5ã¤ã®å€™è£œãƒ†ã‚­ã‚¹ãƒˆ
    'chunks_pos': List[List[List[int]]],                 # ãƒãƒ£ãƒ³ã‚¯ä½ç½®æƒ…å ±
    'labels': List[int],                                 # POS/NEGãƒ©ãƒ™ãƒ« [1,0,0,0,0]
    'dataset_name': str,                                 # å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
    'relevant_chunks': List[List[int]],                  # é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆvLLMåˆ¤å®šï¼‰
    'teacher_scores_japanese-reranker-xsmall-v2': List[float]  # æ•™å¸«ã‚¹ã‚³ã‚¢
}
```

### ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è©³ç´°

- **`id`**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¨ªæ–­ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè­˜åˆ¥å­
- **`query`**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆæ—¥æœ¬èªã¾ãŸã¯è‹±èªï¼‰
- **`texts`**: 5ã¤ã®å€™è£œãƒ†ã‚­ã‚¹ãƒˆï¼ˆ1ã¤ã®POS + 4ã¤ã®NEGï¼‰
- **`chunks_pos`**: å„ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ£ãƒ³ã‚¯ä½ç½®æƒ…å ± `[start, end]`
- **`labels`**: POSã¨NEGã®ãƒ©ãƒ™ãƒ«ï¼ˆå…ˆé ­ãŒå¿…ãšPOS=1ï¼‰
- **`dataset_name`**: å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆms-marcoã€ms-marco-jaã€miracl-jaç­‰ï¼‰
- **`relevant_chunks`**: vLLMãƒ¢ãƒ‡ãƒ«ãŒåˆ¤å®šã—ãŸé–¢é€£ãƒãƒ£ãƒ³ã‚¯ã®0ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
- **`teacher_scores_*`**: japanese-reranker-xsmall-v2ã«ã‚ˆã‚‹æ•™å¸«ã‚¹ã‚³ã‚¢

---

## ğŸš€ **ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ**

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```python
from datasets import load_dataset

# 1. åŸºæœ¬ãƒ­ãƒ¼ãƒ‰
dataset = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'small')

# 2. è¨“ç·´ãƒ‡ãƒ¼ã‚¿å–å¾—
train_data = dataset['train']
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: {len(train_data):,}ä»¶")

# 3. ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
sample = train_data[0]
print(f"ã‚¯ã‚¨ãƒª: {sample['query']}")
print(f"æ•™å¸«ã‚¹ã‚³ã‚¢: {sample['teacher_scores_japanese-reranker-xsmall-v2']}")
print(f"é–¢é€£ãƒãƒ£ãƒ³ã‚¯: {sample['relevant_chunks']}")
print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {sample['dataset_name']}")
```

### å®Ÿè·µçš„ãªä½¿ç”¨ä¾‹

```python
# ãƒãƒ£ãƒ³ã‚¯é–¢é€£æ€§å­¦ç¿’ã®ä¾‹
def extract_training_pairs(sample):
    query = sample['query']
    texts = sample['texts']
    chunks_pos = sample['chunks_pos']
    relevant_chunks = sample['relevant_chunks']
    teacher_scores = sample['teacher_scores_japanese-reranker-xsmall-v2']
    
    training_pairs = []
    for i, (text, text_chunks_pos, text_relevant_chunks, teacher_score) in enumerate(
        zip(texts, chunks_pos, relevant_chunks, teacher_scores)
    ):
        # ãƒãƒ£ãƒ³ã‚¯ã‚’æŠ½å‡º
        chunks = []
        for start, end in text_chunks_pos:
            chunk = text[start:end].strip()
            chunks.append(chunk)
        
        # å­¦ç¿’ãƒšã‚¢ã‚’ä½œæˆ
        training_pairs.append({
            'query': query,
            'text': text,
            'chunks': chunks,
            'relevant_chunks': text_relevant_chunks,
            'teacher_score': teacher_score,
            'label': sample['labels'][i]
        })
    
    return training_pairs

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†
dataset = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', 'small')
train_data = dataset['train']

all_training_pairs = []
for sample in train_data:
    pairs = extract_training_pairs(sample)
    all_training_pairs.extend(pairs)

print(f"å­¦ç¿’ãƒšã‚¢ç·æ•°: {len(all_training_pairs):,}")
```

---

## ğŸ¯ **ç”¨é€”åˆ¥æ¨å¥¨**

| ç”¨é€” | æ¨å¥¨subset | ç†ç”± |
|------|-----------|------|
| **ğŸ”¬ å­¦è¡“ç ”ç©¶ãƒ»è©•ä¾¡** | `full` | åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿ã§å …ç‰¢ãªè©•ä¾¡ãŒå¯èƒ½ |
| **ğŸ‘¨â€ğŸ’» å®Ÿç”¨é–‹ç™º** | `small` | åŠ¹ç‡çš„ãªé–‹ç™ºã¨ãƒ†ã‚¹ãƒˆã«æœ€é© |
| **âš¡ ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°** | `minimal` | é«˜é€Ÿãªæ¦‚å¿µå®Ÿè¨¼ã¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¤œè¨¼ |
| **ğŸŒ è‹±èªNLPã‚·ã‚¹ãƒ†ãƒ ** | `ms-marco-*` | è‹±èªç‰¹åŒ–ã§é«˜å“è³ªãªå­¦ç¿’ |
| **ğŸ—¾ æ—¥æœ¬èªNLPã‚·ã‚¹ãƒ†ãƒ ** | `ja-*` | æ—¥æœ¬èªç‰¹åŒ–ã§æœ€é«˜å“è³ªã®å­¦ç¿’ |
| **ğŸŒ å¤šè¨€èªã‚·ã‚¹ãƒ†ãƒ ** | `full` | 20è¨€èªå¯¾å¿œã®æ±ç”¨çš„ãªå­¦ç¿’ |

---

## ğŸ“ˆ **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ**

### ã‚µã‚¤ã‚ºæ¯”è¼ƒ

| Dataset | Train | Validation | Test | Total |
|---------|-------|------------|------|-------|
| **full** | 1,270,419 | 10,000 | 10,000 | **1,290,419** |
| **small** | 98,450 | 774 | 776 | **100,000** |
| **minimal** | 9,845 | 77 | 78 | **10,000** |
| **ms-marco-full** | 492,930 | 5,000 | 5,000 | **502,930** |
| **ms-marco-small** | 98,011 | 994 | 995 | **100,000** |
| **ms-marco-minimal** | 9,801 | 99 | 100 | **10,000** |
| **ja-full** | 500,298 | 2,999 | 2,999 | **506,296** |
| **ja-small** | 98,815 | 592 | 593 | **100,000** |
| **ja-minimal** | 9,881 | 59 | 60 | **10,000** |

### æ•™å¸«ã‚¹ã‚³ã‚¢å“è³ª

| Dataset Category | POSå¹³å‡ | NEGå¹³å‡ | å“è³ªãƒ©ãƒ³ã‚¯ |
|-----------------|---------|---------|-----------|
| **æ—¥æœ¬èªç‰ˆ** | 0.74-0.98 | 0.05-0.21 | â­â­â­â­â­ |
| **è‹±èªç‰ˆ** | 0.73-0.80 | 0.12-0.18 | â­â­â­â­ |
| **å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç‰ˆ** | 0.78-0.82 | 0.15-0.19 | â­â­â­â­ |

---

## ğŸ”§ **æŠ€è¡“ä»•æ§˜**

### ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

1. **ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**: MS-MARCOã€HPPRCã€MIRACLã‹ã‚‰é«˜å“è³ªãªPOS/NEGãƒšã‚¢ã‚’æŠ½å‡º
2. **å¤šè¨€èªãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°**: 
   - æ—¥æœ¬èª: bunkaiï¼ˆé«˜ç²¾åº¦æ—¥æœ¬èªæ–‡åˆ†å‰²ï¼‰
   - è‹±èª: NLTK sentence_tokenizeï¼ˆé«˜é€Ÿãƒ»é«˜ç²¾åº¦ï¼‰
   - ãã®ä»–: è¨€èªåˆ¥æœ€é©åŒ–ãƒãƒ£ãƒ³ã‚«ãƒ¼
3. **é–¢é€£æ€§åˆ¤å®š**: Query-Context Pruner Multilingualï¼ˆQwen3-4Bï¼‰ã«ã‚ˆã‚‹é–¢é€£ãƒãƒ£ãƒ³ã‚¯æ¤œå‡º
4. **æ•™å¸«ã‚¹ã‚³ã‚¢ä»˜ä¸**: japanese-reranker-xsmall-v2ã«ã‚ˆã‚‹é«˜å“è³ªé–¢é€£æ€§ã‚¹ã‚³ã‚¢
5. **å±¤åŒ–åˆ†å‰²**: dataset_nameåˆ¥ãƒãƒ©ãƒ³ã‚¹è€ƒæ…®åˆ†å‰²

### å“è³ªä¿è¨¼

- **POSæ¤œå‡ºç‡**: 100%ï¼ˆé–¢é€£ãƒãƒ£ãƒ³ã‚¯æ¤œå‡ºã«ãŠã‘ã‚‹é«˜ç²¾åº¦ï¼‰
- **NEGèª¤æ¤œå‡ºç‡**: 5-12%ï¼ˆé©åˆ‡ãªé›£æ˜“åº¦è¨­å®šï¼‰
- **æ•™å¸«ã‚¹ã‚³ã‚¢å¦¥å½“æ€§**: POS/NEGé–“ã®æ˜ç¢ºãªåˆ†é›¢ï¼ˆçµ±è¨ˆçš„æ¤œè¨¼æ¸ˆã¿ï¼‰
- **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§**: å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯å®Œäº†

---

## ğŸ“š **åˆ©ç”¨å¯èƒ½ãªSubsetä¸€è¦§**

```python
# å…¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
available_subsets = [
    'full', 'small', 'minimal',           # å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç‰ˆ
    'ms-marco-full', 'ms-marco-small', 'ms-marco-minimal',  # MS-MARCOè‹±èªç‰ˆ
    'ja-full', 'ja-small', 'ja-minimal'   # æ—¥æœ¬èªç‰ˆ
]

for subset in available_subsets:
    dataset = load_dataset('hotchpotch/wip-query-context-pruner-with-teacher-scores', subset)
    print(f"{subset}: {sum(len(split) for split in dataset.values()):,} ä»¶")
```

---

## âš ï¸ **æ³¨æ„äº‹é …**

- ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯**ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒª**ã§ã™ã€‚ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒå¿…è¦ã§ã™ã€‚
- æ•™å¸«ã‚¹ã‚³ã‚¢ã¯**japanese-reranker-xsmall-v2**ã«ã‚ˆã‚‹è‡ªå‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚
- é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã¯**vLLMãƒ¢ãƒ‡ãƒ«**ã«ã‚ˆã‚‹è‡ªå‹•åˆ¤å®šã§ã™ï¼ˆäººé–“ã«ã‚ˆã‚‹æ¤œè¨¼ãªã—ï¼‰ã€‚
- ç ”ç©¶ãƒ»é–‹ç™ºç›®çš„ã§ã®ä½¿ç”¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚

---

## ğŸ¤ **è²¢çŒ®ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ”¹å–„ææ¡ˆã‚„ãƒã‚°ãƒ¬ãƒãƒ¼ãƒˆã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¡ãƒ³ãƒ†ãƒŠãƒ¼ã¾ã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç‰¹ã«ä»¥ä¸‹ã®è¦³ç‚¹ã§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ­“è¿ã—ã¾ã™ï¼š

- æ•™å¸«ã‚¹ã‚³ã‚¢ã®å¦¥å½“æ€§
- é–¢é€£ãƒãƒ£ãƒ³ã‚¯åˆ¤å®šã®ç²¾åº¦
- æ–°ã—ã„è¨€èªã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¿½åŠ è¦æœ›
- ç”¨é€”åˆ¥æœ€é©åŒ–ã®ææ¡ˆ
