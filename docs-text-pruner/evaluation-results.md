# Provence評価結果まとめ

## 概要

Provenceモデルのチャンクベース評価結果をまとめます。3つのスケール（minimal, small, full）で学習したモデルの性能比較と、最適な閾値設定について記載します。

## チャンクベース評価システム

### predict_context()メソッド
- トークンレベルの予測をチャンク単位に集約
- 2つの閾値による柔軟な制御:
  - `token_threshold`: トークンが関連ありと判定される閾値
  - `chunk_threshold`: チャンク内の関連トークン比率の閾値

### 評価指標
- Precision, Recall, F1, F2スコア
- 圧縮率（削除されたチャンクの割合）
- POS（関連文書）とNEG（非関連文書）の分離評価

## モデル性能比較

### ja-fullデータセットでの評価（F2最適設定: トークン0.3, チャンク0.5）

| モデル | POS Recall | POS FN | NEG Precision | NEG FP | 総合評価 |
|--------|-----------|--------|---------------|--------|----------|
| ja-small | 89.85% | 27 | 75.41% | 30 | 汎化性能高 |
| ja-full | **94.36%** | **15** | **89.13%** | **10** | 最高性能 |

### 主な発見

1. **学習データとテストデータの一致効果**
   - ja-fullモデルはja-fullデータで最高性能
   - 特にPOSデータで誤削除（FN）が大幅に減少

2. **ja-smallモデルの汎化性能**
   - 異なるデータセットでも安定した性能
   - NEGデータのRecallが相対的に高い

3. **F2最適化の効果**
   - 誤削除（FN）を最小化
   - Recallを重視した実用的な設定

## 学習パラメータ比較

### 基本設定

| パラメータ | ja-minimal | ja-small | ja-full |
|-----------|------------|----------|---------|
| エポック数 | 2 | 3 | 1 |
| バッチサイズ | 48 | 32 | 24 |
| 実効バッチサイズ | 48 | 32 | 48 |
| 学習率 | 2e-5 | 2e-5 | 2e-5 |
| Warmup比率 | 0.1 | 0.1 | 0.05 |
| Gradient Accumulation | 1 | 1 | 2 |

### 設計思想
- データ量に応じたエポック数の調整
- メモリ制約を考慮したバッチサイズ設定
- 大規模データでのGradient Accumulation活用

## 推奨設定

### 用途別推奨モデル
1. **高品質・少量データ**: ja-smallモデル
2. **大規模・多様なデータ**: ja-fullモデル
3. **開発・実験用**: ja-minimalモデル

### 閾値設定ガイド
| 目的 | token_threshold | chunk_threshold | 特徴 |
|------|----------------|-----------------|------|
| F2最適（推奨） | 0.3 | 0.5 | 誤削除最小化、高Recall |
| F1最適 | 0.4 | 0.7 | バランス型 |
| F0.5最適 | 0.7 | 0.6 | 高精度、積極的圧縮 |

## 実装のポイント

1. **チャンクベース評価の利点**
   - 実用的な文単位での性能評価
   - トークンレベルのノイズを吸収
   - 閾値による柔軟な調整が可能

2. **POS/NEG分離評価の重要性**
   - 関連/非関連文書で異なる特性
   - それぞれに最適な戦略が必要

3. **F-betaスコアの活用**
   - F2: Recall重視（情報の取りこぼし防止）
   - F0.5: Precision重視（ノイズ除去）
   - 用途に応じた選択が重要