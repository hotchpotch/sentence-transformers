# PruningEncoder評価レポート: pruning_data_ja.jsonデータセット

## 概要

本レポートは、`pruning-config/pruning_data_ja.json`データセットを用いた2つのPruningEncoderモデルの包括的な評価結果をまとめたものです。評価は`scripts/pruning_exec.py`を使用して実施し、異なる閾値でのパフォーマンスを測定しました。

### 評価日時
- 2025年1月14日

### 評価対象モデル
1. **ruri-re310m-full-all** (`output/ruri-re310m-full-all_20250713_143249/final_model`)
   - ベースモデル: cl-nagoya/ruri-v3-30m
   - モード: reranking_pruning（デュアルヘッド）

2. **jpre-xs-full-all** (`output/jpre-xs-full-all_20250713_174655/final_model`)
   - ベースモデル: hotchpotch/japanese-reranker-xsmall-v2
   - モード: reranking_pruning（デュアルヘッド）

### 評価データセット
- **ファイル**: `pruning-config/pruning_data_ja.json`
- **サンプル数**: 30クエリ
- **総コンテキスト数**: 239
  - 関連コンテキスト（正例）: 126
  - 無関連コンテキスト（負例）: 113
- **言語**: 日本語
- **タスク**: クエリに対する関連/無関連コンテキストの判定

## 評価方法

### 実行コマンド
```bash
# ruri-re310m-full-allモデルの評価
python scripts/pruning_exec.py \
    -m output/ruri-re310m-full-all_20250713_143249/final_model \
    --thresholds 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

# jpre-xs-full-allモデルの評価
python scripts/pruning_exec.py \
    -m output/jpre-xs-full-all_20250713_174655/final_model \
    --thresholds 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
```

### 評価メトリクス
- **Accuracy**: 全体の正解率
- **Precision**: 保持したコンテキストのうち実際に関連していた割合
- **Recall**: 関連コンテキストのうち正しく保持した割合
- **F1スコア**: PrecisionとRecallの調和平均
- **F2スコア**: Recallを重視した評価指標（β=2.0）
- **混同行列**:
  - TP (True Positive): 関連コンテキストを正しく保持
  - FP (False Positive): 無関連コンテキストを誤って保持
  - TN (True Negative): 無関連コンテキストを正しく削除
  - FN (False Negative): 関連コンテキストを誤って削除

## 詳細な評価結果

### 1. ruri-re310m-full-allモデル

#### パフォーマンステーブル

| 閾値 | Accuracy | Precision | Recall | F1スコア | F2スコア | TP | FP | TN | FN |
|------|----------|-----------|--------|----------|----------|----|----|----|----|
| 0.1 | 0.5272 | 0.5272 | 1.0000 | 0.6904 | 0.8479 | 126 | 113 | 0 | 0 |
| 0.2 | 0.5439 | 0.5362 | 1.0000 | 0.6981 | 0.8525 | 126 | 109 | 4 | 0 |
| 0.3 | 0.5649 | 0.5478 | 1.0000 | 0.7079 | 0.8583 | 126 | 104 | 9 | 0 |
| 0.4 | 0.6192 | 0.5814 | 0.9921 | 0.7331 | 0.8693 | 125 | 90 | 23 | 1 |
| 0.5 | 0.6611 | 0.6098 | 0.9921 | 0.7553 | 0.8815 | 125 | 80 | 33 | 1 |
| **0.6** | **0.6946** | **0.6359** | **0.9841** | **0.7726** | **0.8870** | **124** | **71** | **42** | **2** |
| 0.7 | 0.7364 | 0.6864 | 0.9206 | 0.7864 | 0.8618 | 116 | 53 | 60 | 10 |
| 0.8 | 0.7490 | 0.7538 | 0.7778 | 0.7656 | 0.7729 | 98 | 32 | 81 | 28 |
| 0.9 | 0.7322 | 0.8523 | 0.5952 | 0.7009 | 0.6334 | 75 | 13 | 100 | 51 |

#### 主要な観察事項
- **最適閾値**: 0.6（F2スコア: 0.8870）
- **特徴**: 広い閾値範囲（0.3-0.6）で安定した高性能
- **強み**: 高閾値でも高いRecallを維持（閾値0.7でも92%）

### 2. jpre-xs-full-allモデル

#### パフォーマンステーブル

| 閾値 | Accuracy | Precision | Recall | F1スコア | F2スコア | TP | FP | TN | FN |
|------|----------|-----------|--------|----------|----------|----|----|----|----|
| 0.1 | 0.5481 | 0.5385 | 1.0000 | 0.7000 | 0.8537 | 126 | 108 | 5 | 0 |
| 0.2 | 0.6151 | 0.5787 | 0.9921 | 0.7310 | 0.8681 | 125 | 91 | 22 | 1 |
| **0.3** | **0.6820** | **0.6276** | **0.9762** | **0.7640** | **0.8786** | **123** | **73** | **40** | **3** |
| 0.4 | 0.7238 | 0.6744 | 0.9206 | 0.7785 | 0.8580 | 116 | 56 | 57 | 10 |
| 0.5 | 0.6820 | 0.6866 | 0.7302 | 0.7077 | 0.7210 | 92 | 42 | 71 | 34 |
| 0.6 | 0.6695 | 0.7765 | 0.5238 | 0.6256 | 0.5603 | 66 | 19 | 94 | 60 |
| 0.7 | 0.5774 | 0.8571 | 0.2381 | 0.3727 | 0.2783 | 30 | 5 | 108 | 96 |
| 0.8 | 0.4937 | 1.0000 | 0.0397 | 0.0763 | 0.0491 | 5 | 0 | 113 | 121 |
| 0.9 | 0.4728 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0 | 0 | 113 | 126 |

#### 主要な観察事項
- **最適閾値**: 0.3（F2スコア: 0.8786）
- **特徴**: 低閾値で最高性能に到達し、その後急速に性能低下
- **弱点**: 閾値0.5以上でRecallが大幅に低下

## モデル比較分析

### 最適閾値でのパフォーマンス比較

| メトリクス | ruri-re310m（閾値0.6） | jpre-xs（閾値0.3） |
|-----------|------------------------|-------------------|
| F2スコア | **0.8870** | 0.8786 |
| Precision | 0.6359 | 0.6276 |
| Recall | **0.9841** | 0.9762 |
| Accuracy | **0.6946** | 0.6820 |
| TP | 124 | 123 |
| FP | 71 | 73 |
| TN | 42 | 40 |
| FN | **2** | 3 |

### 閾値感度分析

1. **ruriモデル**:
   - 閾値0.3-0.6で一貫して高いF2スコア（0.85以上）
   - より「ロバスト」な予測特性
   - 閾値調整の余地が大きい

2. **jpre-xsモデル**:
   - 閾値0.3で最高性能、それ以降は急激に低下
   - より「決定的」な予測特性
   - 最適閾値の選択がクリティカル

### エラー分析

#### False Negative（関連コンテキストの誤削除）
- 両モデルとも非常に低いFN率（2-3件/126件 = 1.6-2.4%）
- RAGシステムでの使用において重要な指標

#### False Positive（無関連コンテキストの誤保持）
- 両モデルとも中程度のFP率（71-73件/113件 = 62.8-64.6%）
- 計算リソースとのトレードオフが必要

## 実用的な推奨事項

### 1. 一般的な使用ケース
- **推奨モデル**: ruri-re310m-full-all（閾値0.6）
- **理由**: 最高のF2スコアと安定した性能

### 2. 高Recall要求のケース（情報の見逃しを最小化）
- **推奨**: 両モデルとも低閾値（0.3）で使用
- **期待性能**: Recall 97-100%、FN 0-3件

### 3. 高Precision要求のケース（ノイズを最小化）
- **推奨モデル**: ruri-re310m-full-all（閾値0.8-0.9）
- **期待性能**: Precision 75-85%、FP 13-32件

### 4. バランス重視のケース
- **推奨モデル**: ruri-re310m-full-all（閾値0.5-0.6）
- **期待性能**: F1 75-77%、総合精度 66-69%

## 結論

両モデルとも優れたプルーニング性能を示しましたが、以下の特徴が明らかになりました：

1. **総合性能**: 両モデルとも最適閾値でF2スコア0.87-0.89を達成
2. **閾値特性**: ruriモデルはより広い閾値範囲で安定、jpre-xsモデルは低閾値に特化
3. **実用性**: ruriモデルが運用時の柔軟性でやや優位

これらの結果は、日本語RAGシステムにおけるコンテキストプルーニングタスクにおいて、両モデルが実用レベルの性能を持つことを示しています。

## 再現方法

```bash
# 1. リポジトリのクローン
git clone https://github.com/hotchpotch/sentence-transformers.git
cd sentence-transformers
git checkout text-pruner

# 2. 環境構築
uv sync

# 3. 評価実行（デフォルトでpruning_data_ja.jsonを使用）
python scripts/pruning_exec.py -m <model_path> --thresholds 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
```

## 付録: 評価データの概要

`pruning-config/pruning_data_ja.json`には以下のようなタスクが含まれています：
- 技術的質問（機械学習、プログラミング等）
- 日常的質問（観光、健康、教育等）
- 各クエリに対して3-5個の関連コンテキストと2個の無関連コンテキスト

詳細なデータ形式については、`docs-text-pruner/specs/data-format-spec.md`を参照してください。