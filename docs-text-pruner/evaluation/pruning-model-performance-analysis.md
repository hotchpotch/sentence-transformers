# Pruning Model Performance Analysis

## 概要

PruningEncoderモデルの実使用における性能評価と問題点の分析。

## 評価実施日

2025年1月11日

## 評価対象モデル

1. **新データセットモデル**: japanese-reranker-xsmall-v2-reranking_pruning-msmarco-ja-small-250711093319
   - データセット: hotchpotch/wip-query-context-pruner-with-teacher-scores-binary-fixed
   
2. **既存MSMARCOモデル**: japanese-reranker-xsmall-v2-reranking_pruning-msmarco-ja-small-250711075148
   - データセット: hotchpotch/wip-msmarco-context-relevance

3. **古いProvenceモデル**: full-provence-weights
   - 初期の実装モデル

## 定量評価結果

### テストセットでの性能（閾値0.3）

| モデル | Pruning F2 | Precision | Recall | Teacher相関 |
|--------|-----------|-----------|---------|------------|
| 新データセット | 0.3759 | 0.5029 | 0.3536 | 0.9323 |
| 既存MSMARCO | 0.3802 | 0.5034 | 0.3583 | 0.9416 |

### 新データセットでの評価

| モデル | Pruning F2 | Teacher MSE | Teacher相関 |
|--------|-----------|-------------|------------|
| 新データセット学習 | 0.2941 | **0.0099** | **0.9669** |
| MSMARCO学習 | 0.3058 | 0.0110 | 0.9649 |

## 実使用評価結果

### スコア分布の問題

すべてのモデルで、関連/無関係文のスコアが適切に分離されていない：

**例：Pythonの特徴（新データセットモデル）**
- 関連文「豊富なライブラリが利用可能」: 0.4704
- 無関係文「犬は忠実なペットです」: **0.5418**（逆転）

### 閾値別の挙動

**閾値0.1での結果（full-provence-weights）**：
- 圧縮率: **4.3%**（ほとんど圧縮されない）
- 削除された文: 1文のみ（「昨日のサッカーの試合は面白かった」）

**閾値別圧縮率**：
| 閾値 | 圧縮率 | 問題点 |
|-----|--------|--------|
| 0.1 | 4.3% | 圧縮効果なし |
| 0.2 | 12.4% | 関連情報も削除開始 |
| 0.3 | 39.8% | 重要情報を大量削除 |

### 具体的な問題例

1. **機械学習の質問**（閾値0.3）：
   - ❌ 削除：「ディープラーニングは機械学習の手法の一つです」（関連）
   - ❌ 削除：「データから自動的にパターンを学習します」（関連）
   - ✅ 維持：「機械学習は人工知能の一分野です」（最初の文のみ）

2. **東京観光の質問**（閾値0.3）：
   - ❌ 削除：「スカイツリーは2012年に開業しました」（関連）
   - ✅ 削除：「プログラミングは楽しい活動です」（無関係）

## 根本的な問題

1. **スコアの収束**：ほぼすべての文が0.4-0.6の狭い範囲に集中
2. **識別能力の欠如**：関連/無関係の区別ができない
3. **位置バイアス**：最初の1-2文以外は削除されやすい
4. **実用的な閾値が存在しない**：低い閾値では圧縮されず、高い閾値では重要情報を削除

## 相対的な性能比較

古いProvenceモデルが最も良い性能を示した：
- 無関係文により低いスコアを付与（0.07-0.23）
- 関連文との差が明確
- ただし、依然として実用レベルには達していない

## 結論

現状のPruningモデルは：
- **F2スコア0.7-0.8という評価結果は実使用と乖離**
- **実用的には使用困難**
- 閾値0.1でも重要情報が削除されるリスク
- RAGのコスト削減目的には不適

## 推奨事項

1. **即時対応**：
   - 極めて低い閾値（0.1以下）での使用
   - 人間によるレビュー必須
   - 本番環境での使用は非推奨

2. **改善提案**：
   - 学習データの品質向上（位置バイアスの除去）
   - 損失関数の再設計
   - 文レベルでの判定メカニズムの導入
   - より現実的な評価データセットの作成