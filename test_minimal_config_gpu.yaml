model_args:
  model_name_or_path: "hotchpotch/japanese-reranker-xsmall-v2"
  classifier_dropout: 0.0

data_args:
  dataset_name: "hotchpotch/wip-msmarco-context-relevance"
  subset: "msmarco-ja-minimal"
  teacher_column: "teacher_scores.japanese-reranker-xsmall-v2"

training_args:
  overwrite_output_dir: true
  optimizer: "adafactor"
  
  # Training parameters
  learning_rate: 5.0e-5
  per_device_train_batch_size: 16
  gradient_accumulation_steps: 4
  max_grad_norm: 1.0
  
  # Optimizer and scheduler
  weight_decay: 0.01
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  
  # Logging and saving
  logging_steps: 5
  save_steps: 500
  save_total_limit: 5
  
  # Mixed precision
  fp16: false
  bf16: true
  
  # Other settings
  dataloader_num_workers: 11
  load_best_model_at_end: false
  num_train_epochs: 1
  max_steps: 10
  
  # eval
  per_device_eval_batch_size: 16
  eval_steps: 500
  
  # Reporting
  report_to: []
  
  # Output directory
  output_dir: "./test_output_gpu"