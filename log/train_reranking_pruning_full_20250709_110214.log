2025-07-09 11:02:14,828 - __main__ - INFO - Starting reranking + pruning training with full dataset
2025-07-09 11:02:14,828 - __main__ - INFO - Loading dataset: hotchpotch/wip-query-context-pruner-with-teacher-scores/ja-full
2025-07-09 11:02:19,718 - __main__ - INFO - Train dataset size: 500298
2025-07-09 11:02:19,718 - __main__ - INFO - Eval dataset size: 2999
2025-07-09 11:02:19,718 - __main__ - INFO - Dataset columns: ['id', 'query', 'texts', 'chunks_pos', 'labels', 'dataset_name', 'relevant_chunks', 'teacher_scores_japanese-reranker-xsmall-v2']
2025-07-09 11:02:19,718 - __main__ - INFO - Initializing PruningEncoder in reranking_pruning mode with base model: hotchpotch/japanese-reranker-xsmall-v2
2025-07-09 11:02:22,062 - __main__ - INFO - Training arguments: {'output_dir': './output/reranking_pruning_full_20250709_110222', 'num_epochs': 1, 'batch_size': 32, 'learning_rate': 2e-05, 'warmup_ratio': 0.1, 'weight_decay': 0.01, 'gradient_accumulation_steps': 2, 'max_grad_norm': 1.0, 'logging_steps': 100, 'eval_steps': 1000, 'save_steps': 1000, 'save_total_limit': 3, 'seed': 42, 'fp16': True, 'dataloader_num_workers': 4}
2025-07-09 11:02:22,063 - __main__ - INFO - Starting training...
2025-07-09 11:02:22,064 - sentence_transformers.pruning.trainer - INFO - ***** Running training *****
2025-07-09 11:02:22,064 - sentence_transformers.pruning.trainer - INFO -   Num examples = 500298
2025-07-09 11:02:22,064 - sentence_transformers.pruning.trainer - INFO -   Num epochs = 1
2025-07-09 11:02:22,064 - sentence_transformers.pruning.trainer - INFO -   Batch size = 32
2025-07-09 11:02:22,064 - sentence_transformers.pruning.trainer - INFO -   Gradient accumulation steps = 2
2025-07-09 11:02:22,064 - sentence_transformers.pruning.trainer - INFO -   Total optimization steps = 15635
2025-07-09 11:02:57,088 - sentence_transformers.pruning.trainer - INFO - Step 100, Loss: 0.2457
2025-07-09 11:03:31,025 - sentence_transformers.pruning.trainer - INFO - Step 200, Loss: 0.1697
2025-07-09 11:04:04,940 - sentence_transformers.pruning.trainer - INFO - Step 300, Loss: 0.1397
2025-07-09 11:04:38,852 - sentence_transformers.pruning.trainer - INFO - Step 400, Loss: 0.1235
2025-07-09 11:05:12,783 - sentence_transformers.pruning.trainer - INFO - Step 500, Loss: 0.1133
2025-07-09 11:05:46,656 - sentence_transformers.pruning.trainer - INFO - Step 600, Loss: 0.1062
2025-07-09 11:06:20,477 - sentence_transformers.pruning.trainer - INFO - Step 700, Loss: 0.1010
2025-07-09 11:06:54,340 - sentence_transformers.pruning.trainer - INFO - Step 800, Loss: 0.0971
2025-07-09 11:07:28,186 - sentence_transformers.pruning.trainer - INFO - Step 900, Loss: 0.0938
2025-07-09 11:08:02,061 - sentence_transformers.pruning.trainer - INFO - Step 1000, Loss: 0.0912
2025-07-09 11:08:02,061 - sentence_transformers.pruning.trainer - INFO - Running evaluation...
2025-07-09 11:08:09,468 - sentence_transformers.pruning.trainer - INFO - Eval loss: 0.1322
2025-07-09 11:08:09,773 - sentence_transformers.pruning.trainer - INFO - New best model saved to ./output/reranking_pruning_full_20250709_110222/checkpoint-1000-best
2025-07-09 11:08:09,773 - sentence_transformers.pruning.trainer - INFO - Saving checkpoint to ./output/reranking_pruning_full_20250709_110222/checkpoint-1000
2025-07-09 11:08:43,900 - sentence_transformers.pruning.trainer - INFO - Step 1100, Loss: 0.0890
2025-07-09 11:09:17,730 - sentence_transformers.pruning.trainer - INFO - Step 1200, Loss: 0.0870
2025-07-09 11:09:51,819 - sentence_transformers.pruning.trainer - INFO - Step 1300, Loss: 0.0854
2025-07-09 11:10:25,735 - sentence_transformers.pruning.trainer - INFO - Step 1400, Loss: 0.0841
2025-07-09 11:10:59,649 - sentence_transformers.pruning.trainer - INFO - Step 1500, Loss: 0.0829
2025-07-09 11:11:33,534 - sentence_transformers.pruning.trainer - INFO - Step 1600, Loss: 0.0818
2025-07-09 11:12:07,377 - sentence_transformers.pruning.trainer - INFO - Step 1700, Loss: 0.0808
2025-07-09 11:12:41,194 - sentence_transformers.pruning.trainer - INFO - Step 1800, Loss: 0.0799
2025-07-09 11:13:15,058 - sentence_transformers.pruning.trainer - INFO - Step 1900, Loss: 0.0791
2025-07-09 11:13:48,932 - sentence_transformers.pruning.trainer - INFO - Step 2000, Loss: 0.0784
2025-07-09 11:13:48,933 - sentence_transformers.pruning.trainer - INFO - Running evaluation...
2025-07-09 11:13:56,180 - sentence_transformers.pruning.trainer - INFO - Eval loss: 0.1256
2025-07-09 11:13:56,483 - sentence_transformers.pruning.trainer - INFO - New best model saved to ./output/reranking_pruning_full_20250709_110222/checkpoint-2000-best
2025-07-09 11:13:56,483 - sentence_transformers.pruning.trainer - INFO - Saving checkpoint to ./output/reranking_pruning_full_20250709_110222/checkpoint-2000
2025-07-09 11:14:30,674 - sentence_transformers.pruning.trainer - INFO - Step 2100, Loss: 0.0777
2025-07-09 11:15:04,579 - sentence_transformers.pruning.trainer - INFO - Step 2200, Loss: 0.0772
2025-07-09 11:15:38,446 - sentence_transformers.pruning.trainer - INFO - Step 2300, Loss: 0.0766
2025-07-09 11:16:12,313 - sentence_transformers.pruning.trainer - INFO - Step 2400, Loss: 0.0760
2025-07-09 11:16:46,172 - sentence_transformers.pruning.trainer - INFO - Step 2500, Loss: 0.0755
2025-07-09 11:17:20,050 - sentence_transformers.pruning.trainer - INFO - Step 2600, Loss: 0.0750
2025-07-09 11:17:53,934 - sentence_transformers.pruning.trainer - INFO - Step 2700, Loss: 0.0746
2025-07-09 11:18:27,802 - sentence_transformers.pruning.trainer - INFO - Step 2800, Loss: 0.0742
2025-07-09 11:19:01,685 - sentence_transformers.pruning.trainer - INFO - Step 2900, Loss: 0.0738
